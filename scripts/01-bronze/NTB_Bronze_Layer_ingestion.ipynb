{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = \"bronze_layer.log\"\n",
    "\n",
    "# Remove any existing handlers\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename=log_file,\n",
    "    level=logging.INFO,\n",
    "    filemode=\"w\",  # Overwrites log file on each run\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "\n",
    "logging.info(\"Logging system initialized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Starting Spark session\")\n",
    "spark = SparkSession.spark = SparkSession.builder.appName('bronze_layer_ingestion').getOrCreate()\n",
    "logging.info(\"Spark session created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bronze_layer_ingestion(input_path):\n",
    "    logs = {}\n",
    "    try:\n",
    "        data = data = spark.read.csv(input_path, sep=',', header = True)\n",
    "        no_of_rows = data.count()\n",
    "        file_name = os.path.splitext(os.path.basename(input_path))[0]\n",
    "        logging.info(f\"Writing data started for file {file_name}\")\n",
    "        output_path = f\"hdfs://0.0.0.0:19000/bronze_layer/global_fashion_sales/{file_name}/\"\n",
    "        data.coalesce(1).write.mode(\"overwrite\")\\\n",
    "            .option('header', 'true')\\\n",
    "            .csv(output_path)\n",
    "        \n",
    "        logs[\"no_of_rows\"] = no_of_rows\n",
    "        logs[\"file_name\"] = file_name\n",
    "        logs[\"output_path\"] = output_path\n",
    "        print(logs)\n",
    "        logging.info(f\"File name:{file_name}, no of rows: {no_of_rows}\")\n",
    "        logging.info(f\"Output Path = {output_path}\")\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error writing CSV: {str(e)}\", exc_info=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_files(directory):\n",
    "    file_paths = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            file_paths.append(os.path.join(root, file))\n",
    "    return file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = r\"D:\\Dev\\global-fashion-sales-dwh\\dataset\"\n",
    "paths = get_all_files(basepath)\n",
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"reading data\")\n",
    "for path in paths:\n",
    "    bronze_layer_ingestion(path)\n",
    "logging.info(\"Writing data completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"stoping spark\")\n",
    "spark.stop()\n",
    "logging.info(\"job completed\")\n",
    "logging.shutdown()  # Close all log handlers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
